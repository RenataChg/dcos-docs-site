---
layout: layout.pug
navigationTitle: Basic configuration settings
title: Basic configuration settings
menuWeight: 20
excerpt: Provides examples for the most common Edge-LB configuration settings
enterprise: false
---

This section provides code examples that illustrate how to set Edge-LB pool configuration options using the Edge-LB REST API with application definitions and sample pool configuration settings.

# Before you begin
Before you create Edge-LB pools and pool configuration files, you should have DC/OS Enterprise cluster nodes installed and ready to use and have previously downloaded and installed the latest Edge-LB packages. 

For information about installing Edge-LB packages, see the [installation](/services/edge-lb/getting-started/installing/) instructions.

# Using Edge-LB for a sample Marathon application
DC/OS services typically run as applications on the Marathon framework. To create a pool configuration file for a Marathon application, you need to know the Mesos `task` name and `port` name. With this information, you can then configure an Edge-LB pool to handle load balancing for that Marathon appllication.

## Identify the task and port for an app
The following code snippet is an excerpt from a sample Marathon app definition. For this sample app definition:
* the `task` name is `my-app`
* the `port` name is `web`

```json
{
  "id": "/my-app",
  ...
  "portDefinitions": [
    {
      "name": "web",
      "protocol": "tcp",
      "port": 0
    }
  ]
}
```

## Configure load balancing for the sample app
After you identify a Marathon application task name and port, you can create a pool configuration for load balancing that app definition. 

1. Create an Edge-LB pool configuration file and name it `app-lb.json`.

    The following code provides a simple example of how to configure an Edge-LB pool named `app-lb` with a pool configuration file named `app-lb.json` to do load balancing for the sample Marathon application:

    ```json
    {
      "apiVersion": "V2",
      "name": "app-lb",
      "count": 1,
      "haproxy": {
        "frontends": [{
          "bindPort": 80,
          "protocol": "HTTP",
          "linkBackend": {
            "defaultBackend": "app-backend"
          }
        }],
        "backends": [{
          "name": "app-backend",
          "protocol": "HTTP",
          "services": [{
            "marathon": {
              "serviceID": "/my-app"
            },
            "endpoint": {
              "portName": "web"
            }
          }]
        }]
      }
    }
    ```

1. Upload the pool configuration to Edge-LB by running the following command:

    ```bash
    dcos edgelb create app-lb.json
    ```

1. Create a Marathon application definition containing the service and name it `my-app.json`. For example:

    ```json
    {
        "id": "/my-app",
        "cmd": "/start $PORT0",
        "instances": 1,
        "cpus": 0.1,
        "mem": 32,
        "container": {
            "type": "DOCKER",
            "docker": {
                "image": "mesosphere/httpd"
            }
        },
        "portDefinitions": [
            {
                "name": "web",
                "protocol": "tcp",
                "port": 0
            }
        ],
        "healthChecks": [
            {
                "portIndex": 0,
                "path": "/",
                "protocol": "HTTP"
            }
        ]
    }
    ```

1. Deploy the service by running the following command:

    ```bash
    dcos marathon app add my-app.json
    ```

# Using static DNS and virtual IP addresses

Internal addresses, such as those generated by Mesos-DNS, Spartan, or the DC/OS layer-4 load-balancer (`dcos-l4lb`) can be exposed outside of the cluster with Edge-LB by using `pool.haproxy.backend.service.endpoint.type: "ADDRESS"`.

Keep in mind that exposing secured internal services to the outside world using an insecure endpoint can make your cluster vulnerable to attack. To mitigate the risk involved when using this feature, you should ensure access to internal endopoints is strictly regulated and monitored.

The following code sample illustrates the Edge-LB pool configuration for a static IP address resolved by Mesos-DNS.

```json
{
  "apiVersion": "V2",
  "name": "dns-lb",
  "count": 1,
  "haproxy": {
    "frontends": [{
      "bindPort": 80,
      "protocol": "HTTP",
      "linkBackend": {
        "defaultBackend": "app-backend"
      }
    }],
    "backends": [{
      "name": "app-backend",
      "protocol": "HTTP",
      "services": [{
        "endpoint": {
          "type": "ADDRESS",
          "address": "myapp.marathon.l4lb.thisdcos.directory",
          "port": 555
        }
      }]
    }]
  }
}
```

# Using Edge-LB with other frameworks and data services

You can use Edge-LB load balancing for frameworks and data services that run tasks not managed by Marathon. For example, you might have tasks managed by Kafka brokers or Cassandra. For tasks that run under other frameworks and data services, you can use the `pool.haproxy.backend.service.mesos` object to filter and select tasks for load balancing.

```json
{
  "apiVersion": "V2",
  "name": "services-lb",
  "count": 1,
  "haproxy": {
    "frontends": [{
      "bindPort": 1025,
      "protocol": "TCP",
      "linkBackend": {
        "defaultBackend": "kafka-backend"
      }
    }],
    "backends": [{
      "name": "kafka-backend",
      "protocol": "TCP",
      "services": [{
        "mesos": {
          "frameworkName": "beta-confluent-kafka",
          "taskNamePattern": "^broker-*$"
        },
        "endpoint": {
          "port": 1025
        }
      }]
    }]
  }
}
```

Other useful fields for selecting frameworks and tasks in `pool.haproxy.backend.service.mesos`:

* `frameworkName`: Exact match
* `frameworkNamePattern`: Regular expression
* `frameworkID`: Exact match
* `frameworkIDPattern`: Regular expression
* `taskName`: Exact match
* `taskNamePattern`: Regular expression
* `taskID`: Exact match
* `taskIDPattern`: Regular expression

# Using host name and SNI routing with VHOSTS

To direct traffic based on the host name to multiple backends for a single port (such as 80 or 443), use `pool.haproxy.frontend.linkBackend`.

## Before you begin
- You must have at least one secure socket layer (SSL) certificiate for the Edge-LB service account. Depending on the security requirements of the cluster, you might have additional SSL certificates that you want to use for access to the linked backend.
- You should create and store a DC/OS secret for each unique SSL certificate you are using. However, one secret is enough if the SSL certificate includes a wildcard that matches several separate websites with the same layer-2 domain namespace. For example, you only need to create and store one secret if you have a certificate to trust any website in the `*.ajuba.net` domain.

- Each secret should contain sections similar to the following:

  ```
  -----BEGIN CERTIFICATE-----
  ...certificate body here...
  -----END CERTIFICATE-----
  -----BEGIN RSA PRIVATE KEY-----
  ...private key body here...
  -----END RSA PRIVATE KEY-----
  ```

  For more information about creating and storing secrets, see [Secrets](/1.12/security/ent/secrets/).

## Sample configuration
After you have created or identified the SSL certificate and stored it securely in DC/OS Secrets, you can route traffic to multiple backends using the `pool.haproxy.frontend.linkBackend` setting as illustrated in the following example:

```json
{
  "apiVersion": "V2",
  "name": "vhost-routing",
  "count": 1,
  "secrets": [
    {
      "secret": "mysslsecret1",
      "file": "mysecretfile1"
    },
    {
      "secret": "mysslsecret2",
      "file": "mysecretfile2"
    }
    ],
  "haproxy": {
<<<<<<< HEAD:pages/services/edge-lb/1.2/pool-configuration/v2-examples/index.md
    "frontends": [
      {
        "bindPort": 80,
        "protocol": "HTTP",
        "linkBackend": {
          "map": [
          {
            "hostEq": "nginx.example.com",
            "backend": "nginx"
          },
          {
            "hostReg": ".*.httpd.example.com",
            "backend": "httpd"
          }
          ]
        }
      },
    {
=======
    "frontends": [{
      "bindPort": 80,
      "protocol": "HTTP",
      "linkBackend": {
        "map": [{
          "hostEq": "nginx.example.com",
          "backend": "nginx"
        },{
          "hostReg": ".*.httpd.example.com",
          "backend": "httpd"
        }]
      }
    },{
>>>>>>> Move my working structure to a new branch, delete old subfolders, replace my working content with changes from Razi 1 March 2019, 4 March 2019, 5 March 2019.:pages/services/edge-lb/how-to-tasks/basic-configuration/index.md
      "bindPort": 443,
      "protocol": "TLS",
      "certificates": [
        "$SECRETS/mysecretfile1",
        "$SECRETS/mysecretfile2"
      ],
      "linkBackend": {
<<<<<<< HEAD:pages/services/edge-lb/1.2/pool-configuration/v2-examples/index.md
        "map": [
          {
            "hostEq": "nginx.example.com",
            "backend": "nginx"
          },
          {
            "hostReg": ".*.httpd.example.com",
            "backend": "httpd"
          }
        ]
=======
        "map": [{
          "hostEq": "nginx.example.com",
          "backend": "nginx"
        },{
          "hostReg": ".*.httpd.example.com",
          "backend": "httpd"
        }]
>>>>>>> Move my working structure to a new branch, delete old subfolders, replace my working content with changes from Razi 1 March 2019, 4 March 2019, 5 March 2019.:pages/services/edge-lb/how-to-tasks/basic-configuration/index.md
      }
    }  
    ],
      "backends": [
        {
          "name": "httpd",
          "protocol": "HTTP",
          "services": [
            {
              "marathon": {
                "serviceID": "/host-httpd"
                },
              "endpoint": {
                "portName": "web"
              }
            }
          ]
        },
    {
      "name": "nginx",
      "protocol": "HTTP",
      "services": [
        {
          "mesos": {
            "frameworkName": "marathon",
            "taskName": "bridge-nginx"
            },
          "endpoint": {
            "portName": "web"
            }
        }
      ]
    }
    ]
  }
}
```

# Using virtual networks

The following example creates a pool that will be launched on the virtual network provided by DC/OS overlay called "dcos". In general, you can launch a pool on any CNI network, by setting `pool.virtualNetworks[].name` to the CNI network name.

```json
{
  "apiVersion": "V2",
  "name": "vnet-lb",
  "count": 1,
  "virtualNetworks": [
    {
      "name": "dcos",
      "labels": {
        "key0": "value0",
        "key1": "value1"
      }
    }
  ],
  "haproxy": {
    "frontends": [{
      "bindPort": 80,
      "protocol": "HTTP",
      "linkBackend": {
        "defaultBackend": "vnet-be"
      }
    }],
    "backends": [{
      "name": "vnet-be",
      "protocol": "HTTP",
      "services": [{
        "marathon": {
          "serviceID": "/my-vnet-app"
        },
        "endpoint": {
          "portName": "my-vnet-port"
        }
      }]
    }]
  }
}
```
